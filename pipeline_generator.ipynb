{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.utils import safe_load_mesh\n",
    "import pickle\n",
    "import sys\n",
    "from models.vae_models import VAE, VAE2, KL_divergence\n",
    "from models.ghd_reconstruct import GHD_Reconstruct\n",
    "from models.losses import wgan_gradient_penalty\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from models.utils import save_models, load_models, plot_wandb\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from pytorch3d.loss import mesh_laplacian_smoothing, mesh_normal_consistency\n",
    "from visualization.gallery import get_fig, get_fig_advanced\n",
    "from IPython.display import Image\n",
    "from models.vae_models import ConditionalVAE4Fouriers\n",
    "from models.mesh_plugins import MeshPlugins\n",
    "from models.vae_datasets import GHDDataset\n",
    "from models.vae_datasets import CenterlineDataset\n",
    "from models.vae_models import CPCDReconstruct\n",
    "from models.mesh_plugins import MeshFusion, p3d_to_trimesh\n",
    "from visualization.gallery import get_mesh_fusion_dataset, get_fig_mesh_fusion\n",
    "\n",
    "B = 15  # number of samples you wish to generate\n",
    "device = torch.device(\"cuda:1\")\n",
    "get_gif = False\n",
    "withscale = True\n",
    "root = ''\n",
    "ghd_chk_root = os.path.join(root, 'checkpoints/ghd_fitting')\n",
    "ghd_run = 'vanilla'\n",
    "ghd_chk_name = 'ghb_fitting_checkpoint_5.pkl'\n",
    "alignment_root = os.path.join(root, 'checkpoints/alignment')\n",
    "canonical_path = os.path.join(root, alignment_root, 'canonical_typeB')\n",
    "eigen_chk = os.path.join(canonical_path, \"canonical_typeB_144.pkl\")\n",
    "canonical_Meshes = safe_load_mesh(os.path.join(canonical_path, 'part_aligned_updated.obj'))\n",
    "cep_chk = os.path.join(canonical_path, \"diff_centreline_checkpoint.pkl\")\n",
    "trimmed_mesh_path = os.path.join(canonical_path, \"part_trimmed_short.obj\")\n",
    "wave_based_trimming = False # if True, use wave-based trimming instead of manually registered mask\n",
    "mesh_plugin = MeshPlugins(canonical_Meshes, cep_chk, trimmed_mesh_path=trimmed_mesh_path, wave_based_trimming=wave_based_trimming)\n",
    "ghd_reconstruct = GHD_Reconstruct(canonical_Meshes, eigen_chk, num_Basis=12**2, device=device)\n",
    "cases = [case for case in os.listdir(ghd_chk_root) if os.path.isdir(os.path.join(ghd_chk_root, case)) and case != \"canonical_typeB\"]\n",
    "ghd_dataset = GHDDataset(ghd_chk_root, ghd_run, ghd_chk_name, ghd_reconstruct, cases, withscale=withscale, normalize=True)\n",
    "ghd_dataloader = DataLoader(ghd_dataset, batch_size=128, shuffle=True)\n",
    "mean_ghd, std_ghd = ghd_dataset.get_mean_std()\n",
    "mean_scale, std_scale = ghd_dataset.get_scale_mean_std()\n",
    "hidden_dim_ghd = 256\n",
    "latent_dim_ghd = 64\n",
    "\n",
    "# load GHD VAE\n",
    "ghd_vae = VAE(ghd_dataset.get_dim(), hidden_dim_ghd, latent_dim_ghd, withscale=withscale).to(device)\n",
    "ghd_vae_chk = os.path.join(\"checkpoints/first_stage_unconditional\", 'vanilla_withscale', 'models_epoch_{}.pth'.format(9000))\n",
    "ghd_vae.load_state_dict(torch.load(ghd_vae_chk)['generator'])\n",
    "ghd_vae.eval()\n",
    "\n",
    "# centerline dataset\n",
    "cl_chk_root = \"./checkpoints/centreline_fitting/stable\"\n",
    "toss_threshold = 0.01\n",
    "centerline_dataset = CenterlineDataset(cl_chk_root, normalize=True, toss_threshold=toss_threshold, device=device)\n",
    "num_branch, num_fourier, fourier_per_branch = centerline_dataset.num_branch, centerline_dataset.num_fourier, centerline_dataset.fourier_per_branch\n",
    "data_loader = DataLoader(centerline_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# cpcd reconstructer\n",
    "cpcd_reconstruct = CPCDReconstruct(num_branch, num_fourier, fourier_per_branch, device=device)\n",
    "\n",
    "# model conf\n",
    "hidden_dim = 256\n",
    "latent_dim = 6\n",
    "basis_include = 12**2\n",
    "batch_size = 128\n",
    "mode = 'train'\n",
    "reload_epoch = 4000\n",
    "meta = 'h256_l6_withscale'\n",
    "log_path = os.path.join(\"./checkpoints/second_stage\", meta)\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "\n",
    "cvae = ConditionalVAE4Fouriers(num_branch, num_fourier, fourier_per_branch, num_basis=basis_include,\n",
    "                            hidden_dim=hidden_dim, latent_dim=latent_dim, dropout=0.0,\n",
    "                            tangent_encoding=True, ghd_reconstruct=ghd_reconstruct, mesh_plugin=mesh_plugin,\n",
    "                            cpcd_reconstruct=cpcd_reconstruct, \n",
    "                            norm_dict=centerline_dataset.return_norm_dict(device), normalize=True,\n",
    "                            ghd_encoding=True,\n",
    "                            withscale=withscale).to(device)\n",
    "\n",
    "# load model\n",
    "if reload_epoch is not None:\n",
    "    chk = torch.load(os.path.join(log_path, 'models_epoch_{}.pth'.format(reload_epoch)))\n",
    "    cvae.load_state_dict(chk['generator'])\n",
    "    print(\"Reloaded from epoch: \", reload_epoch)\n",
    "\n",
    "ghd_fake = ghd_vae.decode(torch.randn(B, latent_dim_ghd).to(device))\n",
    "# ghd_fake = (ghd_fake - mean_ghd.to(ghd_fake.device)) / std_ghd.to(ghd_fake.device)\n",
    "ghd_fake = ghd_vae.decode(torch.randn(B, latent_dim_ghd).to(device))\n",
    "if withscale:\n",
    "    ghd_fake, scale_fake = ghd_fake[0], ghd_fake[1]\n",
    "    scale_fake = scale_fake * std_scale.to(scale_fake.device) + mean_scale.to(scale_fake.device)\n",
    "else:\n",
    "    ghd_fake, scale_fake = ghd_fake, None\n",
    "\n",
    "# meshfusion = MeshFusion(ghd_reconstruct=ghd_reconstruct,\n",
    "#                         mean_ghd=mean_ghd, std_ghd=std_ghd,\n",
    "#                         mesh_plugin=mesh_plugin,\n",
    "#                         device=device)\n",
    "\n",
    "# get_mesh_fusion_dataset(ghd_fake, mean_ghd, std_ghd, cvae,\n",
    "#                         meshfusion, z=None, scale=scale_fake,\n",
    "#                         tgt_dir=os.path.join(os.getcwd(), 'dataset', 'initial'),\n",
    "#                         tangent_shift=[0, 0.075, 0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"plot Umap\"\"\"\n",
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "style = 'fake'\n",
    "load_cluster = True\n",
    "n_clusters = 6\n",
    "# extract real latent \n",
    "ghd_real = next(iter(ghd_dataloader)).to(device)\n",
    "if withscale:\n",
    "    ghd_real, scale_real = ghd_real[:, :-1], ghd_real[:, -1:]\n",
    "else:\n",
    "    scale_real = None\n",
    "\n",
    "# extract latent\n",
    "B = 1024\n",
    "z = torch.randn(B, latent_dim_ghd).to(device)\n",
    "if withscale:\n",
    "    ghd_fake, scale_fake = ghd_vae.decode(z, False)\n",
    "else:\n",
    "    ghd_fake = ghd_vae.decode(z, True)\n",
    "    scale_fake = None\n",
    "mu, logvar = ghd_vae.encode(ghd_fake, scale_fake)\n",
    "z_fake = mu\n",
    "mu, logvar = ghd_vae.encode(ghd_real, scale_real)\n",
    "z_real = mu\n",
    "\n",
    "if style == 'fake':\n",
    "    fit = umap.UMAP(n_neighbors=20)\n",
    "    u = fit.fit_transform(z_fake.detach().cpu().numpy())\n",
    "else:\n",
    "    fit = umap.UMAP(n_neighbors=2)\n",
    "    u = fit.fit_transform(z_real.detach().cpu().numpy())\n",
    "\n",
    "# cluster\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=55).fit(u)\n",
    "labels_fake = kmeans.labels_\n",
    "u_centers = kmeans.cluster_centers_\n",
    "\n",
    "# plot UMAP with different colors for each cluster\n",
    "# Define markers\n",
    "markers = ['o', '^', '*', '+', 'h']\n",
    "unique_labels = np.unique(labels_fake)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "# Plot UMAP with fixed markers and unique colors\n",
    "for i, label in enumerate(unique_labels):\n",
    "    mask = (labels_fake == label)  # Select points for the current cluster\n",
    "    plt.scatter(\n",
    "        u[mask, 0], u[mask, 1],\n",
    "        alpha=0.3,\n",
    "        marker=markers[i % len(markers)],  # Assign marker\n",
    "        color=colors[i]  # Assign color\n",
    "    )\n",
    "    plt.scatter(u_centers[i, 0], u_centers[i, 1], c=colors[i], marker=\"2\", s=100)\n",
    "    # plt.text(u_centers[i, 0], u_centers[i, 1], str(i), fontsize=12, ha='right')\n",
    "plt.show()\n",
    "\n",
    "# Reverse transform u_centers to get the corresponding z values\n",
    "cluster_load_path = os.path.join(\"datasets\", 'cluster.pth')\n",
    "if not os.path.exists(cluster_load_path) or not load_cluster:\n",
    "    z_cluster = torch.Tensor(fit.inverse_transform(u_centers)).to(device)\n",
    "    os.makedirs(\"datasets\", exist_ok=True)\n",
    "    torch.save(z_cluster, cluster_load_path)\n",
    "else:\n",
    "    z_cluster = torch.load(cluster_load_path).to(device)\n",
    "if withscale:\n",
    "    ghd_cluster, scale_cluster = ghd_vae.decode(z_cluster, False)\n",
    "    scale_cluster = ghd_dataset.denorm_scale(scale_cluster)\n",
    "else:\n",
    "    ghd_cluster = ghd_vae.decode(z_cluster)\n",
    "    scale_cluster = None\n",
    "data_cluster = ghd_reconstruct.forward(ghd_cluster, mean_ghd, std_ghd, return_norm=True)\n",
    "fig_cluster = get_fig_advanced(ghd_reconstruct, data_cluster, 4, Title=\"Clusters\", mesh_plugin=mesh_plugin, plot_tangent=True, scale=scale_cluster)\n",
    "plt.show(fig_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We use distance in the latent space as metric for evaluating shape similarity\"\"\"\n",
    "size = 1024\n",
    "radius = 1\n",
    "cluster_idx = 5\n",
    "z_family = z_cluster.unsqueeze(1).repeat(1, size, 1)\n",
    "z_family = z_family + torch.rand_like(z_family) * radius\n",
    "z_family_pick = z_family[cluster_idx]\n",
    "if withscale:\n",
    "    ghd_family, scale_family = ghd_vae.decode(z_family_pick, False)\n",
    "    scale_family = ghd_dataset.denorm_scale(scale_family)\n",
    "else:\n",
    "    ghd_family = ghd_vae.decode(z_family_pick)\n",
    "    scale_family = None\n",
    "\n",
    "data_family = ghd_reconstruct.forward(ghd_family, mean_ghd, std_ghd, return_norm=True)\n",
    "# fig_family = get_fig_advanced(ghd_reconstruct, data_family, 8, Title=\"Clusters\", mesh_plugin=mesh_plugin, plot_tangent=True, scale=scale_family)\n",
    "# plt.show(fig_family)\n",
    "\n",
    "meshfusion = MeshFusion(ghd_reconstruct=ghd_reconstruct,\n",
    "                        mean_ghd=mean_ghd, std_ghd=std_ghd,\n",
    "                        mesh_plugin=mesh_plugin,\n",
    "                        device=device)\n",
    "\n",
    "get_mesh_fusion_dataset(ghd_family, mean_ghd, std_ghd, cvae,\n",
    "                        meshfusion, z=None, scale=scale_family,\n",
    "                        tgt_dir=os.path.join(os.getcwd(), 'datasets', 'stable_64'),\n",
    "                        tangent_shift=[0, 0.05, 0],\n",
    "                        extrusion=[4, 1, 1],\n",
    "                        c_transition=True)\n",
    "\n",
    "# fig_smoothed, merged_mesh_list = get_fig_mesh_fusion(ghd_family, mean_ghd, std_ghd, \n",
    "#                                    ghd_reconstruct, cvae,\n",
    "#                                    meshfusion,\n",
    "#                                    column=8, sub_size=8,\n",
    "#                                    connection_smoothing=True,\n",
    "#                                    title_=None,\n",
    "#                                    scale=scale_family,\n",
    "#                                    control=True,\n",
    "#                                    spline=True,\n",
    "#                                    return_meshes=True,\n",
    "#                                    tangent_shift=[0, 0.05, 0],\n",
    "#                                    extrusion=[6, 1, 1],\n",
    "#                                    c_transition=True)\n",
    "# plt.show(fig_smoothed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
